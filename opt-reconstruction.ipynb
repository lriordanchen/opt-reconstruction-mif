{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPT reconstruction\n",
    "\n",
    "Here is an notebook for using [TomoPy](http://tomopy.readthedocs.io/en/latest/) ([citation here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4181643/pdf/s-21-01188.pdf)) data-cleaning and reconstruction algorithms on image data from the Mesoscopic Imaging Facility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to [install some packages to get this to work](https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/).  Be sure to [install Tomopy](http://tomopy.readthedocs.io/en/latest/install.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make sure you correctly install all packages you need to run this.\n",
    "\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} -c conda-forge tomopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages and modules\n",
    "\n",
    "This notebook reads in hdf5 files and constructs tomograms using the [TomoPy package](https://tomopy.readthedocs.io/en/latest/about.html).\n",
    "\n",
    "matplotlib provide plotting of the result in this notebook. [Paraview](http://www.paraview.org/) or other tools are available for more sophisticated 3D rendering.\n",
    "\n",
    "We will import data as hdf5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lchen\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "from skimage import transform as transf\n",
    "from skimage import img_as_float64\n",
    "#import tensorflow as tf\n",
    "\n",
    "%matplotlib inline                 \n",
    "from ipywidgets import interact  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import an examine data\n",
    "\n",
    "We will import the data from hdf5 files and examine the data using matplotlib to see what cleaning we will need to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path to the tomography data to reconstruct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User must set this, typically put transmission in first, then fluorescence\n",
    "dirname = 'F:\\project\\specimen'\n",
    "\n",
    "fnames = [dirname+r'\\input\\trans.h5', \n",
    "          dirname+r'\\input\\cy5.h5', \n",
    "          dirname+r'\\input\\etgfp.h5',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read hdf5 file structure. \n",
    "\n",
    "This extracts the structure in the hdf5 file (names of keys, number of images, size of images, data type) and displays it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /t0/channel0\n",
      "Shape: (401, 672, 512)\n",
      "Data type: uint16\n",
      "Path: /t0/channel0\n",
      "Shape: (401, 672, 512)\n",
      "Data type: uint16\n",
      "Path: /t0/channel0\n",
      "Shape: (401, 672, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lchen\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\ipykernel_launcher.py:29: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: uint16\n"
     ]
    }
   ],
   "source": [
    "dset_array = array(range(len(fnames)), dtype='|S20')\n",
    "for ix in range(len(fnames)):\n",
    "    filename = fnames[ix]\n",
    "    f = h5py.File(filename, 'r')\n",
    "\n",
    "\n",
    "    def traverse_datasets(hdf_file):\n",
    "\n",
    "        def h5py_dataset_iterator(g, prefix=''):\n",
    "            for key in g.keys():\n",
    "                item = g[key]\n",
    "                path = '{0}/{1}'.format(prefix, key)\n",
    "                if isinstance(item, h5py.Dataset): # test for dataset\n",
    "                    yield (path, item)\n",
    "                elif isinstance(item, h5py.Group): # test for group (go down)\n",
    "                    for ix in h5py_dataset_iterator(item, path):\n",
    "                        yield ix\n",
    "\n",
    "        with h5py.File(hdf_file, 'r') as f:\n",
    "            for path, _ in h5py_dataset_iterator(f):\n",
    "                yield path\n",
    "            \n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        for dset in traverse_datasets(filename):\n",
    "            print('Path:', dset)\n",
    "            dset_array[ix]=dset\n",
    "            print('Shape:', f[dset].shape)\n",
    "            shape_var = f[dset].shape\n",
    "            len_var= sum(len(x) for x in f[dset])\n",
    "            print('Data type:', f[dset].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and save the data from the hdf5 file in variable *proj*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading out channel:  1\n",
      "Reading out channel:  2\n",
      "Reading out channel:  3\n",
      "(3, 401, 672, 512)\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "proj = zeros(shape=(len(fnames), shape_var[0], shape_var[1], shape_var[2]))\n",
    "\n",
    "for ix in range(len(fnames)):\n",
    "    print('Reading out channel: ',ix+1)\n",
    "    filename = fnames[ix]\n",
    "    f = h5py.File(filename, 'r')\n",
    "    dataset=f[dset_array[ix]]\n",
    "    proj[ix] = np.array(dataset[:,:,:])\n",
    "print(proj.shape)\n",
    "num_channels, num_images, image_height, image_width = proj.shape\n",
    "print('Complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to import flat-field and/or dark-field images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename_flat = r'\\input\\cy5_bkgd.tif'\n",
    "#flat = plt.imread(filename_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename_dark = r'\\input\\cy5_bkgd.tif'\n",
    "#dark = plt.imread(filename_dark)\n",
    "\n",
    "#We don't often take dark-field images, so you can simply use an array of homogeneous values from the dark part of an image.\n",
    "#dark_value = proj[1,0,0,0]\n",
    "#dark = np.full((proj.shape[2],proj.shape[3]), dark_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot images from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a53f3d4934640a591b2968afd5b59a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='image_num', max=400), Output()), _dom_classes=('widget-iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_proj(image_num=0)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_num = 1\n",
    "def plot_proj(image_num=0):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(proj[channel_num, image_num, :, :], cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_proj, image_num=(0,num_images-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot sinograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8549455713514054a6e16b3fa8ad9b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='image_num', max=400), Output()), _dom_classes=('widgetâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_sin(image_num=100)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_num = 1\n",
    "def plot_sin(image_num=100):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(proj[channel_num,:,image_num, :], cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_sin, image_num=(0,num_images-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin cleaning data and setting up for reconstruction\n",
    "\n",
    "We will make sure we have the data in the correct formats for Tomopy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the data collection angles.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following assumes 360 degrees rotation divided evenly between all images.\n",
    "theta = np.linspace(0,np.pi*2,num_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have the flat-field and dark-field images (light in absence of sample, and sample in absence of light, respectively), perform the flat-field correction of transmission data: $$ \\frac{proj - dark} {flat - dark} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#proj = tomopy.normalize(proj[0], flat, dark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomopy provides various methods to [find rotation center](http://tomopy.readthedocs.io/en/latest/api/tomopy.recon.rotation.html).  **Set init and ind to help Tomopy find the center for each channel.**\n",
    "\n",
    "\n",
    "If you've run this before, it has saved the data in the input folder and will automatically import it.\n",
    "\n",
    "### Note:\n",
    "*It is important to choose the slice used for the rotation calculation, **ind**, from an area of the sample that doesn't contain any dark spots which the light couldn't pass through.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "init = image_width/2 # Initial guess for the center -- middle of x-axis is a good guess assuming decent alignment\n",
    "ind = 90 #  Index of the slice to be used for reconstruction \n",
    "\n",
    "\n",
    "try:\n",
    "    rot_file = open(dirname+r'\\input\\rotation.pkl', 'rb')\n",
    "    rot_center = pickle.load(rot_file)\n",
    "    rot_file.close()\n",
    "    print('File found')\n",
    "except FileNotFoundError:\n",
    "    rot_center = np.zeros(num_channels)\n",
    "    for ix in range(len(proj)):\n",
    "        rot_center[ix] = tomopy.find_center(proj[0], theta, init=init, ind=ind, tol=0.5)\n",
    "        print(rot_center[ix])\n",
    "    #Pickle for future reference\n",
    "    rot_file = open(dirname+r'\\input\\rotation.pkl','wb')\n",
    "    pickle.dump(rot_center, rot_file)\n",
    "    rot_file.close()\n",
    "print('Complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomopy can align image stack using a [re-projection algorithm](https://www.nature.com/articles/s41598-017-12141-9.pdf).  Indicate whether you want it to run tilt correction or not by setting *tilt_correction = True/False*.\n",
    "\n",
    "This can take a long time, and if you haven't verified that you've chosen the correct rotational center, it will not work properly.  **Therefore, the default is to set tilt_correction = False to not run it.**  However, if previous attempts at reconstructions had tilt-artefacts, set tilt_correction = True and run the algorithm.\n",
    "\n",
    "If you've run this before, it has saved the data in the input folder and will automatically import it.\n",
    "\n",
    "Choose a channel to run the alignment algorithm on.  It's best to use one with low noise and good contrast.\n",
    "\n",
    "*++Note: rotation artefacts look like loops in all the images, tilt artefacts are when the loops occur in only some of the images.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tilt file not found. Using TomoPy to calculate alignment.\n",
      "Aligning channel:  1\n",
      "iter=0, err=76.66061570324099\n",
      "iter=1, err=17.27744194028734\n",
      "iter=2, err=8.713208364316786\n",
      "iter=3, err=4.529900661162451\n",
      "iter=4, err=2.821347195933177\n",
      "iter=5, err=2.193171219946131\n",
      "iter=6, err=1.7606816861659011\n",
      "iter=7, err=1.6155494421403513\n",
      "iter=8, err=1.3564659966250538\n",
      "iter=9, err=1.2124355652982142\n",
      "iter=10, err=1.104536101718726\n",
      "iter=11, err=1.02469507659596\n",
      "iter=12, err=0.9327379053088816\n",
      "iter=13, err=0.8660254037844388\n",
      "iter=14, err=0.8185352771872451\n",
      "161 minutes\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "tilt_correction = False\n",
    "alignment_channel = 1\n",
    "\n",
    "if tilt_correction==True:\n",
    "    #First check if alignment shifts have previously been calculated\n",
    "    try:\n",
    "        tilt_err_file = open(dirname+r'\\input\\tilt_shift.pkl', 'rb')\n",
    "        sy, sx = pickle.load(tilt_err_file)\n",
    "        tilt_err_file.close()\n",
    "        print('File found')\n",
    "\n",
    "    #Otherwise run alignment module\n",
    "    except FileNotFoundError:\n",
    "        print('Tilt file not found. Using TomoPy to calculate alignment.')\n",
    "        \n",
    "        # This can take a long time (~5-10 min/iteration).  Often times, ~10 iterations is sufficient.  Ideally err~<1.\n",
    "\n",
    "        align_params = {'algorithm':'mlem', 'iters':15}\n",
    "\n",
    "        start = datetime.datetime.now()\n",
    "        print(\"Aligning channel: \", alignment_channel)\n",
    "        proj_align_channel, sy , sx, conv_channel = tomopy.prep.alignment.align_joint(proj[alignment_channel], theta, \n",
    "                                                                                      center=rot_center[alignment_channel], \n",
    "                                                                                      **align_params)\n",
    "        end = datetime.datetime.now()\n",
    "        print( int((end - start).total_seconds()/60), 'minutes' )\n",
    "\n",
    "        #Pickle for future reference\n",
    "        tilt_err_file = open(dirname+r'\\input\\tilt_shift.pkl','wb')\n",
    "        pickle.dump([sy,sx], tilt_err_file)\n",
    "        tilt_err_file.close()\n",
    "    print(\"Complete.\")\n",
    "else:\n",
    "        print('No alignment correction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply alignment to all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning channel:  1\n",
      "Aligning channel:  2\n",
      "Aligning channel:  3\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "# This will take a minute\n",
    "\n",
    "if tilt_correction==True:\n",
    "    align_proj = zeros(shape=proj.shape)\n",
    "    for ch in range(num_channels):\n",
    "        print('Aligning channel: ', ch+1)\n",
    "        channel_proj = np.copy(proj[ch])\n",
    "        for ix in range(num_images):\n",
    "            tform = transf.SimilarityTransform(translation=(sy[ix], sx[ix]))\n",
    "            channel_proj[ix] = transf.warp(channel_proj[ix], tform)\n",
    "        align_proj[ch] = channel_proj\n",
    "    print('Complete.')\n",
    "else:\n",
    "    print('No alignment correction')\n",
    "    align_proj=np.copy(proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check alignment looks correct before saving over projections -- if tilt_correction = False, this doesn't change anything and shows the original projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2739a68b64946229410ca1958664568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='image_num', max=400), Output()), _dom_classes=('widget-iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_proj_align(image_num=0)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_num = 1\n",
    "def plot_proj_align(image_num=0):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(align_proj[channel_num, image_num, :, :], cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_proj_align, image_num=(0,num_images-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it looks reasonable, save new projection -- again, if tilt_projection = False, this does not change anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj=np.copy(align_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $$ -log(proj) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lchen\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be446efd899d43ba8e3dc43e30c5dbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='image_num', max=400), Output()), _dom_classes=('widget-iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_proj(image_num=0)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_inv = zeros(shape = proj.shape)\n",
    "proj_inv = -np.log(proj)\n",
    "\n",
    "channel_num = 1\n",
    "def plot_proj(image_num=0):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(proj_inv[channel_num, image_num, :, :], cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_proj, image_num=(0,num_images-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct projections.  \n",
    "Tomopy offers a number of [algorithms and filters](https://tomopy.readthedocs.io/en/latest/api/tomopy.recon.algorithm.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing channel:  1\n",
      "Reconstructing channel:  2\n",
      "Reconstructing channel:  3\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "# Algorithm/filters can be chosen according to needs.  \n",
    "params = {'algorithm':'gridrec','filter_name':'butterworth'}\n",
    "\n",
    "recon = zeros(shape=(num_channels, image_height, image_width, image_width))\n",
    "for ix in range(num_channels):\n",
    "    print('Reconstructing channel: ', ix+1)\n",
    "    recon_channel = tomopy.recon(align_proj[ix], theta, center=rot_center[ix], \n",
    "                                 **params\n",
    "                                  )\n",
    "    recon[ix] = recon_channel\n",
    "print('Complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask each reconstructed slice with a circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(len(recon)):\n",
    "    recon[ix] = tomopy.circ_mask(recon[ix], axis=0, ratio=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check axis=2 to see if data from reconstructions can be back-constructed to original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874e64d945d74f3d91004ffa41f500ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=250, description='image_num', max=511), Output()), _dom_classes=('widgetâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_back(image_num=250)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_num = 1\n",
    "def plot_back(image_num=250):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(recon[channel_num,:, image_num, :], cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_back, image_num=(0,recon.shape[2]-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above image looks nothing like the original, there are a couple things you can do:\n",
    "\n",
    "- Check that **rot-center** makes sense, and possibly re-evaluate your choices of **init** and **ind** for finding the rotational center.  \n",
    "- Check that theta was calculated correctly (in radians, **not** degrees)\n",
    "- Check that the files imported correctly.\n",
    "- Add in flat-field corrections to clean your data.\n",
    "\n",
    "Then you can re-try the reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot image from axis=0 to see reconstructed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660cde1401e741dd8248fa2bfc75024b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=250, description='image_num', max=671), Output()), _dom_classes=('widgetâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_recon(image_num=250)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_num = 1\n",
    "def plot_recon(image_num=250):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.imshow(recon[channel_num,image_num,:, :], cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_recon, image_num=(0,recon.shape[1]-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply filters to final data to clean up noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering along axis:  2 / 2\n",
      "Filtering channel:  1\n",
      "Filtering channel:  2\n",
      "Filtering channel:  3\n",
      "Filtering along axis:  2 / 2\n",
      "Filtering channel:  1\n",
      "Filtering channel:  2\n",
      "Filtering channel:  3\n",
      "Complete.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2554825ff9ee4514b17e012e5344bd20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=250, description='image_num', max=671), Output()), _dom_classes=('widgetâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_filter(image_num=250)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_axis_list = [1,2]\n",
    "\n",
    "\n",
    "for ax in range(len(filter_axis_list)):\n",
    "    print('Filtering along axis: ', ax+1, '/', len(filter_axis_list))\n",
    "    filtered = [zeros(shape=(image_height,image_width, image_width))]\n",
    "    for ch in range(len(proj)):\n",
    "        print('Filtering channel: ', ch+1)\n",
    "        filtered_channel = tomopy.misc.corr.median_filter(recon[ch], size=5, axis=ax)\n",
    "        #filtered_channel = tomopy.misc.corr.sobel_filter(recon[ch], axis=ax)\n",
    "        filtered = np.append(filtered, [filtered_channel], axis=0)\n",
    "    filtered = np.delete(filtered, (0), axis = 0)\n",
    "print('Complete.')\n",
    "\n",
    "\n",
    "channel_num = 1\n",
    "def plot_filter(image_num=250):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.imshow(filtered[channel_num,image_num,:, :], cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_filter, image_num=(0,filtered.shape[1]-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data in output folder\n",
    "\n",
    "Create an output folder and export as hdf5 (**REWRITE NAMES OF FILES FROM PREVIOUS RUN IF THEY ARE DIFFERENT**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing channel:  1\n",
      "Writing channel:  2\n",
      "Writing channel:  3\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "#Set folder and names of outputs, must be same number as number of inputs, ideally use same labels\n",
    "file_output = [dirname+r'\\output\\trans.h5', \n",
    "               dirname+r'\\output\\cy5.h5',\n",
    "               dirname+r'\\output\\etgfp.h5'\n",
    "               ]\n",
    "\n",
    "for ix in range(len(file_output)):\n",
    "    print('Writing channel: ', ix+1)\n",
    "    file_output_h5 = file_output[ix]\n",
    "    archive = h5py.File(file_output_h5, 'w')\n",
    "    archive['recon'] = filtered[ix]\n",
    "    archive.close()\n",
    "    \n",
    "print('Complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
