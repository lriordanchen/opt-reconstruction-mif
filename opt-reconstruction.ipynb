{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPT reconstruction\n",
    "\n",
    "Here is an notebook for using [TomoPy](http://tomopy.readthedocs.io/en/latest/) ([citation here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4181643/pdf/s-21-01188.pdf)) data-cleaning and reconstruction algorithms on image data from the Mesoscopic Imaging Facility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to [install some packages to get this to work](https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/).  Be sure to [install Tomopy](http://tomopy.readthedocs.io/en/latest/install.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make sure you correctly install all packages you need to run this.\n",
    "\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} -c conda-forge tomopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages and modules\n",
    "\n",
    "This notebook reads in hdf5 files and constructs tomograms using the [TomoPy package](https://tomopy.readthedocs.io/en/latest/about.html).\n",
    "\n",
    "matplotlib and ipywidgets provide plotting of the result in this notebook. [Paraview](http://www.paraview.org/) or other tools are available for more sophisticated 3D rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "from skimage import transform as transf\n",
    "from skimage import img_as_float64\n",
    "\n",
    "%matplotlib inline                 \n",
    "from ipywidgets import interact  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import an examine data\n",
    "\n",
    "We will import the data from hdf5 files and examine the data using matplotlib to see what cleaning we will need to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path to the tomography data to reconstruct and input names of the hdf5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User must set this, typically put transmission in first, then fluorescence\n",
    "dirname = 'D:\\Data_folder\\sample_name'\n",
    "\n",
    "fnames = [dirname+r'\\input\\trans.h5', \n",
    "          dirname+r'\\input\\cy5.h5', \n",
    "          dirname+r'\\input\\ET.h5',\n",
    "          dirname+r'\\input\\YFP.h5'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read hdf5 file structure. \n",
    "\n",
    "This extracts the structure in the hdf5 file (names of keys, number of images, size of images, data type) and displays it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /t0/channel0\n",
      "Shape: (400, 672, 512)\n",
      "Data type: uint16\n",
      "Path: /t0/channel0\n",
      "Shape: (400, 672, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lchen\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\ipykernel_launcher.py:29: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: uint16\n",
      "Path: /t0/channel0\n",
      "Shape: (400, 672, 512)\n",
      "Data type: uint16\n",
      "Path: /t0/channel0\n",
      "Shape: (400, 672, 512)\n",
      "Data type: uint16\n"
     ]
    }
   ],
   "source": [
    "dset_array = array(range(len(fnames)), dtype='|S20')\n",
    "for ix in range(len(fnames)):\n",
    "    filename = fnames[ix]\n",
    "    f = h5py.File(filename, 'r')\n",
    "\n",
    "\n",
    "    def traverse_datasets(hdf_file):\n",
    "\n",
    "        def h5py_dataset_iterator(g, prefix=''):\n",
    "            for key in g.keys():\n",
    "                item = g[key]\n",
    "                path = '{0}/{1}'.format(prefix, key)\n",
    "                if isinstance(item, h5py.Dataset): # test for dataset\n",
    "                    yield (path, item)\n",
    "                elif isinstance(item, h5py.Group): # test for group (go down)\n",
    "                    for ix in h5py_dataset_iterator(item, path):\n",
    "                        yield ix\n",
    "\n",
    "        with h5py.File(hdf_file, 'r') as f:\n",
    "            for path, _ in h5py_dataset_iterator(f):\n",
    "                yield path\n",
    "            \n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        for dset in traverse_datasets(filename):\n",
    "            print('Path:', dset)\n",
    "            dset_array[ix]=dset\n",
    "            print('Shape:', f[dset].shape)\n",
    "            shape_var = f[dset].shape\n",
    "            len_var= sum(len(x) for x in f[dset])\n",
    "            print('Data type:', f[dset].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and save the data from the hdf5 file in variable *proj*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading out channel:  1\n",
      "Reading out channel:  2\n",
      "Reading out channel:  3\n",
      "Reading out channel:  4\n",
      "(4, 400, 672, 512)\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "proj = zeros(shape=(len(fnames), shape_var[0], shape_var[1], shape_var[2]))\n",
    "\n",
    "for ix in range(len(fnames)):\n",
    "    print('Reading out channel: ',ix+1)\n",
    "    filename = fnames[ix]\n",
    "    f = h5py.File(filename, 'r')\n",
    "    dataset=f[dset_array[ix]]\n",
    "    proj[ix] = np.array(dataset[:,:,:])\n",
    "print(proj.shape)\n",
    "num_channels, num_images, image_height, image_width = proj.shape\n",
    "print('Complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to import flat-field and/or dark-field images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_bool = False\n",
    "\n",
    "if flat_bool==True:\n",
    "    filename_flat = r'\\input\\cy5_bkgd.tif'\n",
    "    flat = plt.imread(filename_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_bool = False\n",
    "\n",
    "if dark_bool=True:\n",
    "    filename_dark = r'\\input\\cy5_bkgd.tif'\n",
    "    dark = plt.imread(filename_dark)\n",
    "\n",
    "if flat_bool==True and dark_bool=False:\n",
    "#We don't often take dark-field images, so you can simply use an array of homogeneous values from the dark part of an image.\n",
    "    dark_value = proj[1,0,0,0]\n",
    "    dark = np.full((proj.shape[2],proj.shape[3]), dark_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot images from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab302e7937aa49f68843f4fecfe15488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='image_num', max=399), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_proj(image_num=0)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_num = 1\n",
    "def plot_proj(image_num=0):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(proj[channel_num, image_num, :, :], cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_proj, image_num=(0,num_images-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot sinograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43f3de75bd54e6791a87765476a851c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='image_num', max=399), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_sin(image_num=100)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_num = 1\n",
    "def plot_sin(image_num=100):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(proj[channel_num,:,image_num, :], cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_sin, image_num=(0,num_images-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin cleaning data and setting up for reconstruction\n",
    "\n",
    "We will make sure we have the data in the correct formats for Tomopy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the data collection angles.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following assumes 360 degrees rotation divided evenly between all images.\n",
    "theta = np.linspace(0,np.pi*2,num_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have the flat-field and dark-field images (light in absence of sample, and sample in absence of light, respectively), perform the flat-field correction of transmission data: $$ \\frac{proj - dark} {flat - dark} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if flat_bool==True:\n",
    "    proj[0] = tomopy.normalize(proj[0], flat, dark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomopy provides various methods to [find rotation center](http://tomopy.readthedocs.io/en/latest/api/tomopy.recon.rotation.html).  **There are a couple ways to do rotation, you may need to try both.**\n",
    "\n",
    "\n",
    "If you've run this before, it has saved the data in the input folder and will automatically import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256.5\n",
      "255.75\n",
      "256.5\n",
      "255.0\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "image_180 = int(floor(num_images/2)) #assuming 360 degrees of rotation, this is image 180 degrees apart from first image\n",
    "\n",
    "try:\n",
    "    rot_file = open(dirname+r'\\input\\rotation.pkl','rb')\n",
    "    rot_center = pickle.load(rot_file)\n",
    "    rot_file.close()\n",
    "    print('File found')\n",
    "except FileNotFoundError:\n",
    "    rot_center = np.zeros(num_channels)\n",
    "    for ch in range(num_channels):\n",
    "        #rot_center[ch] = tomopy.find_center_vo(proj[ch])\n",
    "        rot_center[ch] = tomopy.find_center_pc(proj[ch][0],proj[ch][image_180])\n",
    "        print(rot_center[ch])\n",
    "    #Pickle for future reference\n",
    "    rot_file = open(dirname+r'\\input\\rotation.pkl','wb')\n",
    "    pickle.dump(rot_center, rot_file)\n",
    "    rot_file.close()\n",
    "print('Complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomopy can align image stack using a [re-projection algorithm](https://www.nature.com/articles/s41598-017-12141-9.pdf).  Indicate whether you want it to run tilt correction or not by setting *tilt_correction = True/False*.\n",
    "\n",
    "This can take a long time.  It's recommended to try it at first without tilt correction if you are confident that the sample is relatively well-aligned and the rotation stage is reliable.  However, if previous attempts at reconstructions had tilt-artefacts, set tilt_correction = True and run the algorithm.\n",
    "\n",
    "If you've run this before, it has saved the data in the input folder and will automatically import it.\n",
    "\n",
    "Choose a channel to run the alignment algorithm on.  It's best to use one with low noise and good contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No alignment correction\n"
     ]
    }
   ],
   "source": [
    "tilt_correction = False\n",
    "alignment_channel = 1\n",
    "\n",
    "if tilt_correction==True:\n",
    "    #First check if alignment shifts have previously been calculated\n",
    "    try:\n",
    "        tilt_file = open(dirname+r'\\input\\tilt_shift.pkl', 'rb')\n",
    "        sy, sx = pickle.load(tilt_file)\n",
    "        tilt_file.close()\n",
    "        print('File found')\n",
    "\n",
    "    #Otherwise run alignment module\n",
    "    except FileNotFoundError:\n",
    "        print('Tilt file not found. Using TomoPy to calculate alignment.')\n",
    "        \n",
    "        # This can take a long time (~5-10 min/iteration).  Often times, ~10 iterations is sufficient.  Ideally err<1.\n",
    "\n",
    "        align_params = {'algorithm':'mlem', 'iters':10}\n",
    "\n",
    "        start = datetime.datetime.now()\n",
    "        print(\"Aligning channel: \", alignment_channel)\n",
    "        proj_align_channel, sy , sx, conv_channel = tomopy.prep.alignment.align_joint(proj[alignment_channel], theta, \n",
    "                                                                                      center=rot_center[alignment_channel], \n",
    "                                                                                      **align_params)\n",
    "        end = datetime.datetime.now()\n",
    "        print( int((end - start).total_seconds()/60), 'minutes' )\n",
    "\n",
    "        #Pickle for future reference\n",
    "        tilt_file = open(dirname+r'\\input\\tilt_shift.pkl','wb')\n",
    "        pickle.dump([sy,sx], tilt_file)\n",
    "        tilt_file.close()\n",
    "    print(\"Complete.\")\n",
    "else:\n",
    "        print('No alignment correction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply alignment to all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No alignment correction\n"
     ]
    }
   ],
   "source": [
    "# This will take a minute\n",
    "\n",
    "if tilt_correction==True:\n",
    "    align_proj = zeros(shape=proj.shape)\n",
    "    for ch in range(num_channels):\n",
    "        print('Aligning channel: ', ch+1)\n",
    "        channel_proj = np.copy(proj[ch])\n",
    "        for ix in range(num_images):\n",
    "            tform = transf.SimilarityTransform(translation=(sy[ix], sx[ix]))\n",
    "            channel_proj[ix] = transf.warp(channel_proj[ix], tform)\n",
    "        align_proj[ch] = channel_proj\n",
    "    print('Complete.')\n",
    "else:\n",
    "    print('No alignment correction')\n",
    "    align_proj=np.copy(proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check alignment looks correct before saving over projections -- if tilt_correction = False, this doesn't change anything and shows the original projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baab5ae474124a779f28d403ac9a17c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='image_num', max=399), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_proj_align(image_num=0)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_num = 1\n",
    "def plot_proj_align(image_num=0):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(align_proj[channel_num, image_num, :, :], cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_proj_align, image_num=(0,num_images-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it looks reasonable, save new projection -- again, if tilt_projection = False, this does not change anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj=np.copy(align_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $$ -log(proj) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c139ad1a94147db8d4ad23ceff99660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='image_num', max=399), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_proj(image_num=0)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_inv = zeros(shape = proj.shape)\n",
    "proj_inv = -np.log(proj)\n",
    "\n",
    "channel_num = 1\n",
    "def plot_proj(image_num=0):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(proj_inv[channel_num, image_num, :, :], cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_proj, image_num=(0,num_images-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct projections.  \n",
    "Tomopy offers a number of [algorithms and filters](https://tomopy.readthedocs.io/en/latest/api/tomopy.recon.algorithm.html).\n",
    "\n",
    "Algorithm/filters can be chosen according to needs. \n",
    "- fbp is standard filtered back projection.\n",
    "- gridrec is very fast, and reconstructs reasonably well.\n",
    "- Iterative methods like mlem, art, and sirt generally outperform direct Fourier-based reconstruction methods, however require many iterations at ~4-6 min/iter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing channel:  1\n",
      "Reconstructing channel:  2\n",
      "Reconstructing channel:  3\n",
      "Reconstructing channel:  4\n",
      "1173 minutes\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "params = {'algorithm':'mlem', 'num_iter':10}\n",
    "\n",
    "recon = zeros(shape=(num_channels, image_height, image_width, image_width))\n",
    "start = datetime.datetime.now()\n",
    "for ix in range(num_channels):\n",
    "    print('Reconstructing channel: ', ix+1)\n",
    "    recon_channel = tomopy.recon(align_proj[ix], theta, center=rot_center[ix], \n",
    "                                 **params\n",
    "                                  )\n",
    "    recon[ix] = recon_channel\n",
    "end = datetime.datetime.now()\n",
    "print( int((end - start).total_seconds()/60), 'minutes' )\n",
    "print('Complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask each reconstructed slice with a circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(len(recon)):\n",
    "    recon[ix] = tomopy.circ_mask(recon[ix], axis=0, ratio=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check axis=2 to see if data from reconstructions can be back-constructed to original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d702e239214bdfb1eff8893ed320f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=250, description='image_num', max=511), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_back(image_num=250)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_num = 1\n",
    "def plot_back(image_num=250):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(recon[channel_num,:, image_num, :], cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_back, image_num=(0,recon.shape[2]-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above image looks nothing like the original, there are a couple things you can do:\n",
    "\n",
    "- Check that **rot-center** makes sense.  \n",
    "- Check that theta was calculated correctly (in radians, **not** degrees)\n",
    "- Check that the files imported correctly.\n",
    "- Add in flat-field corrections to clean your data.\n",
    "\n",
    "Then you can re-try the reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot image from axis=0 to see reconstructed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bad461ecb7244c3af367f407fb6377c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=250, description='image_num', max=671), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_recon(image_num=250)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_num = 1\n",
    "def plot_recon(image_num=250):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.imshow(recon[channel_num,image_num,:, :], cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_recon, image_num=(0,recon.shape[1]-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can apply filters to final data to clean up noise, but default would be filter_bool = False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No filter applied\n",
      "Complete.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11faf29a55f44f46b6537e8ebe72d56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=250, description='image_num', max=671), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_filter(image_num=250)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_bool = False\n",
    "\n",
    "if filter_bool == True:  \n",
    "    filter_axis_list = [1,2]\n",
    "    filtered = np.copy(recon)\n",
    "    for ax in range(len(filter_axis_list)):\n",
    "        print('Filtering along axis: ', ax+1, '/', len(filter_axis_list))\n",
    "        for ch in range(len(proj)):\n",
    "            print('Filtering channel: ', ch+1)\n",
    "            filtered[ch] = tomopy.misc.corr.median_filter(filtered[ch], size=3, axis=ax)\n",
    "else:\n",
    "    print('No filter applied')\n",
    "    filtered=np.copy(recon)\n",
    "print('Complete.')\n",
    "\n",
    "\n",
    "channel_num = 1\n",
    "def plot_filter(image_num=250):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.imshow(filtered[channel_num,image_num,:, :], cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_filter, image_num=(0,filtered.shape[1]-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data in output folder\n",
    "\n",
    "**Create an output folder**, set it in the output file name below, and we will data export as hdf5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing channel:  1\n",
      "Writing channel:  2\n",
      "Writing channel:  3\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "#Set folder and names of outputs, must be same number as number of inputs, ideally use same labels\n",
    "file_output = [dirname+r'\\output\\trans.h5', \n",
    "               dirname+r'\\output\\cy5.h5',\n",
    "               dirname+r'\\output\\etgfp.h5'\n",
    "               ]\n",
    "\n",
    "for ix in range(len(file_output)):\n",
    "    print('Writing channel: ', ix+1)\n",
    "    file_output_h5 = file_output[ix]\n",
    "    archive = h5py.File(file_output_h5, 'w')\n",
    "    archive['recon'] = filtered[ix]\n",
    "    archive.close()\n",
    "    \n",
    "print('Complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
